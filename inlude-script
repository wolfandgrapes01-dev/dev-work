import os
import re
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
import io

# --------------------------
# 配置
# --------------------------
root_dir = r"C:\path\to\your\root"  # 修改为你的根目录
extensions = ('.cpp', '.c', '.h', '.hpp')
include_pattern = re.compile(r'#include\s+[<"](.+?)[>"]')

# --------------------------
# 1️⃣ 构建文件索引
# --------------------------
file_index = defaultdict(list)
for dirpath, dirnames, filenames in os.walk(root_dir):
    dirnames[:] = [d for d in dirnames if d.lower() != ".svn"]
    for filename in filenames:
        if filename.endswith(extensions):
            file_index[filename].append(os.path.abspath(os.path.join(dirpath, filename)))

# --------------------------
# 2️⃣ 找 src 文件夹
# --------------------------
def find_src_dirs(root):
    src_dirs = []
    for dirpath, dirnames, _ in os.walk(root):
        dirnames[:] = [d for d in dirnames if d.lower() != ".svn"]
        for d in dirnames:
            if d.lower() == "src":
                src_dirs.append(os.path.join(dirpath, d))
    return src_dirs

# --------------------------
# 3️⃣ 收集所有 src 文件（全局去重依据）
# --------------------------
src_dirs = find_src_dirs(root_dir)
all_files = []

for src in src_dirs:
    for dirpath, _, filenames in os.walk(src):
        for filename in filenames:
            if filename.endswith(extensions):
                all_files.append(os.path.abspath(os.path.join(dirpath, filename)))

all_root_files = set(all_files)
global_seen_in_root = set()  # 全局去重 root 下依赖对象

# --------------------------
# 4️⃣ 文件解析函数（全局去重 & 系统依赖过滤）
# --------------------------
def parse_file(full_path):
    includes_list = []
    try:
        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
            in_block_comment = False
            for line in f:
                stripped = line.strip()
                # 多行注释
                if in_block_comment:
                    if '*/' in stripped:
                        in_block_comment = False
                        stripped = stripped.split('*/',1)[1]
                    else:
                        continue
                if '/*' in stripped:
                    if '*/' in stripped:
                        stripped = re.sub(r'/\*.*?\*/', '', stripped)
                    else:
                        in_block_comment = True
                        stripped = stripped.split('/*',1)[0]
                # 单行注释
                stripped = re.sub(r'//.*', '', stripped).strip()
                if not stripped:
                    continue

                match = include_pattern.search(stripped)
                if match:
                    include_file = match.group(1)
                    if include_file.startswith('<') or include_file.startswith('/'):
                        continue

                    candidate = os.path.join(os.path.dirname(full_path), include_file)
                    if os.path.exists(candidate):
                        include_path = os.path.abspath(candidate)
                    else:
                        basename = os.path.basename(include_file)
                        if basename in file_index:
                            include_path = file_index[basename][0]
                        else:
                            continue

                    # root 下全局去重
                    if include_path in all_root_files:
                        if include_path not in global_seen_in_root:
                            global_seen_in_root.add(include_path)
                            includes_list.append(include_path)
                    else:
                        includes_list.append(include_path)

    except Exception as e:
        print(f"⚠️ 读取失败: {full_path} - {e}")

    return full_path, includes_list

# --------------------------
# 5️⃣ 多线程解析 src 文件夹
# --------------------------
print(f"🔍 找到 {len(all_files)} 个源文件，开始解析...")
dependency_map = {}
with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
    for full_path, includes in tqdm(executor.map(parse_file, all_files), total=len(all_files), desc="解析文件进度"):
        if includes:
            dependency_map[full_path] = includes

# --------------------------
# 6️⃣ 树形生成（递归）
# --------------------------
def build_tree_lines(file_path, prefix='', visited=None):
    if visited is None:
        visited = set()
    if file_path in visited:
        return [prefix + "(循环依赖)"]
    visited.add(file_path)

    lines = []
    deps = dependency_map.get(file_path, [])
    count = len(deps)
    for i, dep in enumerate(deps):
        branch = "└─ " if i == count - 1 else "├─ "
        sub_prefix = "   " if i == count - 1 else "│  "
        lines.append(prefix + branch + dep)
        if dep in dependency_map:
            lines.extend(build_tree_lines(dep, prefix + sub_prefix, visited))
    visited.remove(file_path)
    return lines

# --------------------------
# 7️⃣ 写入 TXT（边生成边写入，低内存 + tqdm）
# --------------------------
output_file = os.path.join(root_dir, "dependencies_tree.txt")

# 预估总行数（用于进度条）
def estimate_total_lines(dep_map):
    total = 0
    def count_lines(file_path, visited=None):
        nonlocal total
        if visited is None:
            visited = set()
        if file_path in visited:
            total += 1
            return
        visited.add(file_path)
        total += 1
        for dep in dep_map.get(file_path, []):
            count_lines(dep, visited)
        visited.remove(file_path)
    for f in dep_map:
        count_lines(f)
    return total

total_lines = estimate_total_lines(dependency_map)

with io.open(output_file, 'w', encoding='utf-8', buffering=1024*1024) as f:  # 1MB 缓冲
    pbar = tqdm(total=total_lines, desc="写入 TXT 进度")
    for top_file in dependency_map:
        f.write(top_file + "\n")
        pbar.update(1)
        tree_lines = build_tree_lines(top_file)
        for line in tree_lines:
            f.write(line + "\n")
            pbar.update(1)
        f.write("\n")
        pbar.update(1)
    pbar.close()

print(f"\n✅ 依赖树已输出到：{output_file}")