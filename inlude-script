import os
import re
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
import io

# --------------------------
# 設定
# --------------------------
root_dir = r"C:\path\to\your\root"  # ルートディレクトリ
project_name = "ProjectA"            # 分析対象のプロジェクト名
extensions = ('.cpp', '.c', '.h', '.hpp')
include_pattern = re.compile(r'#include\s+[<"](.+?)[>"]')

# --------------------------
# 1️⃣ ファイルインデックス作成（root 下のすべてのファイルを登録）
# --------------------------
file_index = defaultdict(list)
for dirpath, dirnames, filenames in os.walk(root_dir):
    dirnames[:] = [d for d in dirnames if d.lower() != ".svn"]
    for filename in filenames:
        if filename.endswith(extensions):
            file_index[filename].append(os.path.abspath(os.path.join(dirpath, filename)))

# --------------------------
# 2️⃣ ProjectA/src 下の解析対象ファイルを収集
# --------------------------
project_a_src = os.path.join(root_dir, project_name, "src")
top_files = []
for dirpath, dirnames, filenames in os.walk(project_a_src):
    dirnames[:] = [d for d in dirnames if d.lower() != ".svn"]
    for filename in filenames:
        if filename.endswith(extensions):
            top_files.append(os.path.abspath(os.path.join(dirpath, filename)))

# --------------------------
# 3️⃣ root 下の全ファイルリスト（重複排除用）
# --------------------------
all_root_files = set()
for dirpath, dirnames, filenames in os.walk(root_dir):
    dirnames[:] = [d for d in dirnames if d.lower() != ".svn"]
    for filename in filenames:
        if filename.endswith(extensions):
            all_root_files.add(os.path.abspath(os.path.join(dirpath, filename)))

global_seen_in_root = set()  # root 下依存オブジェクトの重複除外

# --------------------------
# 4️⃣ ファイル解析関数
# --------------------------
def parse_file(full_path):
    includes_list = []
    try:
        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
            in_block_comment = False
            for line in f:
                stripped = line.strip()
                # ブロックコメント除外
                if in_block_comment:
                    if '*/' in stripped:
                        in_block_comment = False
                        stripped = stripped.split('*/', 1)[1]
                    else:
                        continue
                if '/*' in stripped:
                    if '*/' in stripped:
                        stripped = re.sub(r'/\*.*?\*/', '', stripped)
                    else:
                        in_block_comment = True
                        stripped = stripped.split('/*', 1)[0]
                # 行コメント除外
                stripped = re.sub(r'//.*', '', stripped).strip()
                if not stripped:
                    continue

                match = include_pattern.search(stripped)
                if match:
                    include_file = match.group(1)
                    if include_file.startswith('<') or include_file.startswith('/'):
                        continue

                    candidate = os.path.join(os.path.dirname(full_path), include_file)
                    if os.path.exists(candidate):
                        include_path = os.path.abspath(candidate)
                    else:
                        basename = os.path.basename(include_file)
                        if basename in file_index:
                            include_path = file_index[basename][0]
                        else:
                            continue

                    # 重複除外ロジック
                    if include_path in all_root_files:
                        if include_path not in global_seen_in_root:
                            global_seen_in_root.add(include_path)
                            includes_list.append(include_path)
                    else:
                        includes_list.append(include_path)

        # ▼ 新機能：対応する .cpp を自動探索して追加
        if full_path.endswith(('.h', '.hpp')):
            cpp_candidate = os.path.splitext(os.path.basename(full_path))[0] + ".cpp"
            if cpp_candidate in file_index:
                cpp_path = file_index[cpp_candidate][0]
                if cpp_path in all_root_files and cpp_path not in global_seen_in_root:
                    global_seen_in_root.add(cpp_path)
                    includes_list.append(cpp_path)

    except Exception as e:
        print(f"⚠️ 読み取り失敗: {full_path} - {e}")

    return full_path, includes_list

# --------------------------
# 5️⃣ マルチスレッド解析
# --------------------------
print(f"🔍 {len(top_files)} 個の ProjectA/src ファイルを解析中...")
dependency_map = {}
with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
    for full_path, includes in tqdm(executor.map(parse_file, top_files), total=len(top_files), desc="解析進行中"):
        if includes:
            dependency_map[full_path] = includes

# --------------------------
# 6️⃣ 再帰ツリー構築
# --------------------------
def build_tree_lines(file_path, prefix='', visited=None):
    if visited is None:
        visited = set()
    if file_path in visited:
        return [prefix + "(循環依存)"]
    visited.add(file_path)

    lines = []
    deps = dependency_map.get(file_path, [])
    count = len(deps)
    for i, dep in enumerate(deps):
        branch = "└─ " if i == count - 1 else "├─ "
        sub_prefix = "   " if i == count - 1 else "│  "
        lines.append(prefix + branch + dep)
        if dep in dependency_map:
            lines.extend(build_tree_lines(dep, prefix + sub_prefix, visited))
    visited.remove(file_path)
    return lines

# --------------------------
# 7️⃣ TXT 出力（進捗表示付き）
# --------------------------
output_file = os.path.join(root_dir, f"{project_name}_dependencies_tree.txt")

def estimate_total_lines(dep_map):
    total = 0
    def count_lines(file_path, visited=None):
        nonlocal total
        if visited is None:
            visited = set()
        if file_path in visited:
            total += 1
            return
        visited.add(file_path)
        total += 1
        for dep in dep_map.get(file_path, []):
            count_lines(dep, visited)
        visited.remove(file_path)
    for f in dep_map:
        count_lines(f)
    return total

total_lines = estimate_total_lines(dependency_map)

with io.open(output_file, 'w', encoding='utf-8', buffering=1024*1024) as f:
    pbar = tqdm(total=total_lines, desc="TXT 出力進行中")
    for top_file in dependency_map:
        f.write(top_file + "\n")
        pbar.update(1)
        tree_lines = build_tree_lines(top_file)
        for line in tree_lines:
            f.write(line + "\n")
            pbar.update(1)
        f.write("\n")
        pbar.update(1)
    pbar.close()

print(f"\n✅ {project_name} の依存ツリー（.cpp 自動補完付き）を出力しました：{output_file}")