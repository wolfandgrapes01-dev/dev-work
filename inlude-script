import os
import re
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm  # 进度条

root_dir = r"C:\path\to\your\root"
extensions = ('.cpp', '.c', '.h', '.hpp')
include_pattern = re.compile(r'#include\s+[<"](.+?)[>"]')

# --------------------------
# 1️⃣ 构建文件索引
# --------------------------
file_index = defaultdict(list)
for dirpath, dirnames, filenames in os.walk(root_dir):
    dirnames[:] = [d for d in dirnames if d.lower() != ".svn"]
    for filename in filenames:
        if filename.endswith(extensions):
            file_index[filename].append(os.path.abspath(os.path.join(dirpath, filename)))

# --------------------------
# 2️⃣ 找 src 文件夹
# --------------------------
def find_src_dirs(root):
    src_dirs = []
    for dirpath, dirnames, _ in os.walk(root):
        dirnames[:] = [d for d in dirnames if d.lower() != ".svn"]
        for d in dirnames:
            if d.lower() == "src":
                src_dirs.append(os.path.join(dirpath, d))
    return src_dirs

# --------------------------
# 3️⃣ 文件解析函数
# --------------------------
def parse_file(full_path):
    includes = []
    try:
        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
            in_block_comment = False
            for line in f:
                stripped = line.strip()
                # 多行注释
                if in_block_comment:
                    if '*/' in stripped:
                        in_block_comment = False
                        stripped = stripped.split('*/',1)[1]
                    else:
                        continue
                if '/*' in stripped:
                    if '*/' in stripped:
                        stripped = re.sub(r'/\*.*?\*/', '', stripped)
                    else:
                        in_block_comment = True
                        stripped = stripped.split('/*',1)[0]
                # 单行注释
                stripped = re.sub(r'//.*', '', stripped).strip()
                if not stripped:
                    continue

                match = include_pattern.search(stripped)
                if match:
                    include_file = match.group(1)
                    # 优先同目录
                    candidate = os.path.join(os.path.dirname(full_path), include_file)
                    if os.path.exists(candidate):
                        include_path = os.path.abspath(candidate)
                    else:
                        basename = os.path.basename(include_file)
                        if basename in file_index:
                            include_path = file_index[basename][0]
                        else:
                            include_path = include_file  # 外部库或找不到
                    includes.append(include_path)
    except Exception as e:
        print(f"⚠️ 读取失败: {full_path} - {e}")
    return full_path, includes

# --------------------------
# 4️⃣ 多线程解析 src 文件夹（安全 tqdm）
# --------------------------
dependency_map = {}
src_dirs = find_src_dirs(root_dir)
all_files = []

for src in src_dirs:
    for dirpath, _, filenames in os.walk(src):
        for filename in filenames:
            if filename.endswith(extensions):
                all_files.append(os.path.abspath(os.path.join(dirpath, filename)))

print(f"🔍 找到 {len(all_files)} 个源文件，开始解析...")

with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
    # 使用 map + tqdm，保证进度条走完表示所有任务完成
    for full_path, includes in tqdm(executor.map(parse_file, all_files), total=len(all_files)):
        if includes:
            dependency_map[full_path] = includes

# --------------------------
# 5️⃣ 生成树形结构（递归）
# --------------------------
def build_tree(file_path, prefix='', visited=None):
    if visited is None:
        visited = set()
    if file_path in visited:
        return [prefix + "(循环依赖)"]
    visited.add(file_path)

    lines = []
    deps = dependency_map.get(file_path, [])
    count = len(deps)
    for i, dep in enumerate(deps):
        branch = "└─ " if i == count - 1 else "├─ "
        sub_prefix = "   " if i == count - 1 else "│  "
        lines.append(prefix + branch + dep)
        if dep in dependency_map:
            lines.extend(build_tree(dep, prefix + sub_prefix, visited))
    visited.remove(file_path)
    return lines

# --------------------------
# 6️⃣ 输出树形 TXT（批量写入，提升性能）
# --------------------------
output_file = os.path.join(root_dir, "dependencies_tree.txt")

all_output_lines = []
for top_file in dependency_map:
    all_output_lines.append(top_file + "\n")
    tree_lines = build_tree(top_file)
    all_output_lines.extend(line + "\n" for line in tree_lines)
    all_output_lines.append("\n")  # 顶层文件间加空行

# 一次性写入文件
with open(output_file, 'w', encoding='utf-8') as f:
    f.writelines(all_output_lines)

print(f"\n✅ 依赖树已输出到：{output_file}")